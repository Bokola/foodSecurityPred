{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script produces the figures as shown in \"Predicting Food-Security Crises in the Horn of Africa Using Machine Learning\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################\n",
    "################################################### IMPORT PACKAGES  ###################################################\n",
    "#####################################################################################################################\n",
    "\n",
    "from time import sleep\n",
    "import os\n",
    "import sys\n",
    "import random as python_random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime \n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import geoplot as gplt\n",
    "import geoplot.crs as gcrs\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import seaborn as sns\n",
    "import mapclassify as mc\n",
    "from matplotlib.colors import LinearSegmentedColormap,ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "from here import here\n",
    "\n",
    "# SKLEARN \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit,RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, explained_variance_score, recall_score, precision_score, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# Tensorflow\n",
    "#import tensorflow as tf\n",
    "\n",
    "# others\n",
    "import pydot\n",
    "## FEATURE EXPLANATION\n",
    "import shap \n",
    "from colour import Color\n",
    "import contextily as ctx\n",
    "#import jupyterthemes as jt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /home/basil-owiti/foodSecurityPred\n"
     ]
    }
   ],
   "source": [
    "# Change directory to the parent (foodSecurityPred)\n",
    "if os.path.basename(os.getcwd()) != 'foodSecurityPred':\n",
    "    os.chdir('..')\n",
    "\n",
    "# Add the current directory to sys.path so 'src' is importable\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.getcwd())\n",
    "\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")\n",
    "# Now you can do: from src.ML_functions import load_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/basil-owiti/foodSecurityPred/ML_results/\n"
     ]
    }
   ],
   "source": [
    "CORE= here()\n",
    "BASE= CORE+'/ML_results/' # 'C:/Users/USER/Documents/ML/\n",
    "print(BASE)\n",
    "VECTOR_FOLDER=CORE+'/input_collector/Vector/'    \n",
    "FSO_FOLDER= CORE+'/input_collector/FC_data/FEWS/FEWS_OUTLOOKS'\n",
    "paper_plots= CORE+'/paper_figs/'\n",
    "\n",
    "extent='HOA'\n",
    "experiment= 'RUN_FINAL_20' #EXP_POP_20 # REV_BASE_20\n",
    "region_list=['HOA'] # region for which the model runned --> 'HOA' or 'Somalia','Kenya', 'Ethiopia'\n",
    "aggregation='cluster' # county, cluster, all \n",
    "pop_weighted=True # used to choose the right prediction dataframe from FEWS internal predictions (the FEWS-NET outlooks spatially weighted to calculate county mean)\n",
    "\n",
    "# crises onset variables \n",
    "method='crisis_onset'\n",
    "threshold= 3 # threshold for crisis onset \n",
    "co_buffer=0.05 # this is the allowance of the crisis onset (co) threshold to deviate with this buffer. For example, turkana was 2.98 with the whole county in crisis except a very small area. We want this to still be classified as crisis onset. \n",
    "\n",
    "if aggregation=='county':\n",
    "    region_list=['HOA']\n",
    "\n",
    "if aggregation=='cluster':\n",
    "    cluster_list=['ap','p','other'] # cluster you want to plot\n",
    "\n",
    "if aggregation=='county':\n",
    "    cluster_list=['no_cluster']\n",
    "if aggregation=='all':\n",
    "    cluster_list=['no_cluster']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_RUN_FINAL_20_HOA_ap\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'raw_model_output_cluster_RUN_FINAL_20_HOA_ap.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[10], line 18\u001b[0m\n",
      "\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# load and concat preds \u001b[39;00m\n",
      "\u001b[1;32m     17\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(BASE)\n",
      "\u001b[0;32m---> 18\u001b[0m preds_storage\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraw_model_output_\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscenario\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "\u001b[1;32m     19\u001b[0m preds_storage[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m cluster\n",
      "\u001b[1;32m     22\u001b[0m features_df_full\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_importances_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(scenario), index_col\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m])\n",
      "\n",
      "File \u001b[0;32m~/foodSecurityPred/.venv/lib/python3.11/site-packages/pandas/io/excel/_base.py:481\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n",
      "\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n",
      "\u001b[1;32m    480\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;32m--> 481\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n",
      "\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[1;32m    489\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    490\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    491\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m~/foodSecurityPred/.venv/lib/python3.11/site-packages/pandas/io/excel/_base.py:1604\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n",
      "\u001b[1;32m   1601\u001b[0m         ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m-> 1604\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   1605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n",
      "\u001b[1;32m   1606\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m   1608\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[1;32m   1609\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m   1610\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m   1611\u001b[0m         )\n",
      "\n",
      "File \u001b[0;32m~/foodSecurityPred/.venv/lib/python3.11/site-packages/pandas/io/excel/_base.py:1452\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n",
      "\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minspect_excel_format\u001b[39m(\n",
      "\u001b[1;32m   1418\u001b[0m     content_or_path: FilePath \u001b[38;5;241m|\u001b[39m ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n",
      "\u001b[1;32m   1419\u001b[0m     storage_options: StorageOptions \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[1;32m   1420\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m   1422\u001b[0m \u001b[38;5;124;03m    Inspect the path or content of an excel file and get its format.\u001b[39;00m\n",
      "\u001b[1;32m   1423\u001b[0m \n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   1450\u001b[0m \u001b[38;5;124;03m        If resulting stream does not have an XLS signature and is not a valid zipfile.\u001b[39;00m\n",
      "\u001b[1;32m   1451\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;32m-> 1452\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   1453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n",
      "\u001b[1;32m   1454\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n",
      "\u001b[1;32m   1455\u001b[0m         stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n",
      "\u001b[1;32m   1456\u001b[0m         stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/foodSecurityPred/.venv/lib/python3.11/site-packages/pandas/io/common.py:935\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n",
      "\u001b[1;32m    926\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n",
      "\u001b[1;32m    927\u001b[0m             handle,\n",
      "\u001b[1;32m    928\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    931\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m    932\u001b[0m         )\n",
      "\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    934\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n",
      "\u001b[0;32m--> 935\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    936\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n",
      "\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'raw_model_output_cluster_RUN_FINAL_20_HOA_ap.xlsx'"
     ]
    }
   ],
   "source": [
    "preds_storage_master=pd.DataFrame()\n",
    "features_df_full_master=pd.DataFrame()\n",
    "if extent=='HOA':\n",
    "    for region in region_list:\n",
    "        if region!='HOA':\n",
    "            region_extent= 'country_level'\n",
    "        else:\n",
    "            region_extent='HOA'\n",
    "\n",
    "\n",
    "        for cluster in cluster_list:\n",
    "\n",
    "            scenario='%s_%s_%s_%s'%(aggregation, experiment, region, cluster) # load the specific scenario name \n",
    "            print(scenario)\n",
    "\n",
    "            # load and concat preds \n",
    "            os.chdir(BASE)\n",
    "            preds_storage=pd.read_excel('raw_model_output_%s.xlsx'%(scenario), index_col='date') \n",
    "            preds_storage['cluster']= cluster\n",
    "\n",
    "\n",
    "            features_df_full=pd.read_excel('feature_importances_%s.xlsx'%(scenario), index_col=[0])\n",
    "            features_df_full['cluster']= cluster  \n",
    "\n",
    "            ############################# assign country to rows #############################\n",
    "            if region_extent=='HOA':\n",
    "                KEN_units=gpd.read_file(VECTOR_FOLDER+'geo_boundaries/Kenya/County.shp').COUNTY\n",
    "                SOM_units=gpd.read_file(VECTOR_FOLDER+'geo_boundaries/Somalia/Som_Admbnda_Adm2_UNDP.shp').admin2Name\n",
    "                ETH_units=gpd.read_file(VECTOR_FOLDER+'geo_boundaries/Ethiopia/eth_admbnda_adm2_csa_bofedb_2021.shp').ADM2_EN\n",
    "\n",
    "                # assign Kenya to rows if county is in Kenya\n",
    "                features_df_full.loc[features_df_full['county'].isin(KEN_units), 'country']='Kenya'\n",
    "                preds_storage.loc[preds_storage['county'].isin(KEN_units), 'country']='Kenya'\n",
    "                # assign Somalia to rows if county is in Somalia\n",
    "                features_df_full.loc[features_df_full['county'].isin(SOM_units), 'country']='Somalia'\n",
    "                preds_storage.loc[preds_storage['county'].isin(SOM_units), 'country']='Somalia'\n",
    "                # assign Ethiopia to rows if county is in Ethiopia\n",
    "                features_df_full.loc[features_df_full['county'].isin(ETH_units), 'country']='Ethiopia'\n",
    "                preds_storage.loc[preds_storage['county'].isin(ETH_units), 'country']='Ethiopia'\n",
    "                \n",
    "                if aggregation=='all':\n",
    "                    # assign lhz \n",
    "                    lhz=pd.read_excel(CORE+'input_collector/'+'data_master.xlsx')\n",
    "                    lhz=lhz[['county', 'lhz']]\n",
    "                    lhz=lhz.drop_duplicates(subset=['county'], keep='first')\n",
    "                    preds_storage['cluster']=preds_storage['county'].map(lhz.set_index('county')['lhz'])\n",
    "                    \n",
    "                    \n",
    "            else: \n",
    "                # assign country \n",
    "                preds_storage['country']=region\n",
    "                # assign lhz \n",
    "                lhz=pd.read_excel(CORE+'input_collector/'+'data_master.xlsx')\n",
    "                lhz=lhz[['county', 'lhz']]\n",
    "                lhz=lhz.drop_duplicates(subset=['county'], keep='first')\n",
    "                preds_storage['cluster']=preds_storage['county'].map(lhz.set_index('county')['lhz'])\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "            preds_storage_master=pd.concat([preds_storage_master, preds_storage], axis=0)\n",
    "            features_df_full_master=pd.concat([features_df_full_master, features_df_full], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the FEWS predictions to the predictions dataframe \n",
    "if pop_weighted==True:\n",
    "    FSO_df=pd.read_excel(FSO_FOLDER+'/fews_lead_df_pop_weighted.xlsx')\n",
    "else:\n",
    "    FSO_df=pd.read_excel(FSO_FOLDER+'/fews_lead_df.xlsx')\n",
    "\n",
    "FSO_df.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "FSO_df.rename(columns={'target_date': 'date'}, inplace=True)\n",
    "\n",
    "# Add FSO to the dataframe with our ML forecasts \n",
    "df1= FSO_df.copy() \n",
    "df2= preds_storage_master.copy() \n",
    "\n",
    "# df 1 preps\n",
    "df1.rename(columns={'target_date': 'date'}, inplace=True)\n",
    "df1.drop('country', axis=1, inplace=True)\n",
    "# df 2 preps \n",
    "df2.reset_index(inplace=True)\n",
    "\n",
    "#merge operation \n",
    "merged_df= pd.merge(df2, df1, how='left', left_on=['county','date', 'lead'], right_on = ['county','date', 'lead'])\n",
    "preds_storage_master=merged_df.copy()\n",
    "\n",
    "# create an extra obs column for the preds_storage_master, which are nan for nan's in the FEWS_prediction column \n",
    "preds_storage_master['OBS_FSO']=preds_storage_master['observed'][~np.isnan(preds_storage_master['FEWS_prediction'])]\n",
    "preds_storage_master=preds_storage_master.set_index('date') # new\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate HR and FR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cont_calc(truth_input, preds_input, method_input, threshold_input, co_buffer):\n",
    "        ############################ change verif  #############################\n",
    "#         if method_input=='change':\n",
    "            \n",
    "#             increases=truth_input.diff()\n",
    "#             increases.dropna(inplace=True)\n",
    "#             increases= increases.where(increases>=threshold_input,9999)\n",
    "#             increases= increases.where(increases==9999,1)\n",
    "#             increases= increases.where(increases==1,0)\n",
    "\n",
    "#             increases_pred= preds_input.diff()\n",
    "#             increases_pred.dropna(inplace=True)\n",
    "#             increases_pred= increases_pred.where(increases_pred>=threshold_input,9999)\n",
    "#             increases_pred= increases_pred.where(increases_pred==9999,1)\n",
    "#             increases_pred= increases_pred.where(increases_pred==1,0)\n",
    "\n",
    "#             truth_bin= increases.copy()\n",
    "#             preds_bin= increases_pred.copy()\n",
    "\n",
    "\n",
    "#         if method_input =='extremes':\n",
    "#             truth_bin=np.where(truth_input>=threshold_input, 1, 0)\n",
    "#             preds_bin=np.where(preds_input>=threshold_input, 1, 0)\n",
    "            \n",
    "            \n",
    "        \n",
    "        if method_input =='crisis_onset':\n",
    "\n",
    "            co= truth_input.where(truth_input>=(threshold_input-co_buffer),0) # sets all non-crisis to 0 \n",
    "            \n",
    "            co= co.where(co==0,1) # sets all the crisis to 1 \n",
    "            co= np.where((co==1) & (co!=co.shift(1)),1,0) # flags 1s that are the first in a row\n",
    "            \n",
    "            if len(co)>0:\n",
    "                co[0]=0 # make the first value 0 (we dont know if its an onset)\n",
    "            \n",
    "            co_pred= preds_input.where(preds_input>=(threshold_input-co_buffer),0) # sets all non-crisis to 0 \n",
    "            co_pred= co_pred.where(co_pred==0,1)# sets all the crisis to 1 \n",
    "            co_pred= np.where((co_pred==1) & (co_pred!=co_pred.shift(1)),1,0) # flags 1s that are the first in a row    \n",
    "            \n",
    "            if len(co_pred)>0:\n",
    "                co_pred[0] = 0 # make the first value 0 (we dont know if its an onset)\n",
    "            \n",
    "            truth_bin= co.copy()\n",
    "            preds_bin= co_pred.copy()\n",
    "\n",
    "        # event count \n",
    "        event_count=truth_bin.sum()\n",
    "\n",
    "        # f1-score\n",
    "        recall=recall_score(truth_bin, preds_bin, zero_division=0) #updatet sklearn to get np.nan option\n",
    "        precision=precision_score(truth_bin, preds_bin,zero_division=0)\n",
    "        if (precision+recall)==0:\n",
    "            f1=0\n",
    "        else: \n",
    "            f1= 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "        # cont scores\n",
    "        h=truth_bin*preds_bin\n",
    "        fa= (preds_bin==1) & (truth_bin==0)\n",
    "        fa=fa.astype(float)\n",
    "        cn= (preds_bin==0) & (truth_bin==0)\n",
    "        cn=cn.astype(float)\n",
    "        ms= (preds_bin==0) & (truth_bin==1)\n",
    "        ms=ms.astype(float)\n",
    "\n",
    "        # false alarm rate \n",
    "        if (fa.sum()+cn.sum())>0: # check if there are non-events\n",
    "            far=fa.sum()/(fa.sum()+cn.sum())\n",
    "        else:\n",
    "            far=np.nan\n",
    "    \n",
    "\n",
    "        # hit rate\n",
    "        if (h.sum()+ms.sum())>0: #  check if there are hit events.. \n",
    "            hr=h.sum()/(h.sum()+ms.sum())\n",
    "        else:\n",
    "            hr=np.nan\n",
    "        \n",
    "        return co, co_pred,event_count,h,fa,ms,cn,hr,far,recall,precision,f1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_storage_master['county'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# code to calculate scores on county level \n",
    "\n",
    "\n",
    "\n",
    "################# SCORES CALCULATIONS ##############\n",
    "eval_stats=pd.DataFrame()\n",
    "for unit in preds_storage_master['county'].unique():\n",
    "\n",
    "    ############## Load unit preds ##############\n",
    "    preds_ini=preds_storage_master[preds_storage_master['county']==unit]\n",
    "\n",
    "\n",
    "    ############## Load lead preds ##############\n",
    "    for lead in preds_ini['lead'].unique():\n",
    "        preds=preds_ini[preds_ini['lead']==lead]\n",
    "\n",
    "        # observations\n",
    "        truth=preds['observed'] # observed\n",
    "        truth_FSO=preds['OBS_FSO'] # observed, but nans in FSO are nan in obs \n",
    "        truth_FSO=truth_FSO[~np.isnan(truth_FSO)]# need to delete nans from the arrays \n",
    "\n",
    "        # predictions\n",
    "        base1=preds['base1_preds']\n",
    "        base2=preds['base2_preds']\n",
    "        #lr=preds['lr']\n",
    "        fews_preds=preds['FEWS_prediction']\n",
    "        fews_preds=fews_preds[~np.isnan(fews_preds)] # needed to delete nans from the arrays \n",
    "\n",
    "\n",
    "\n",
    "        preds=preds['prediction']\n",
    "        ##################################################################\n",
    "        \n",
    "        #######################  ML model SCORES ################################\n",
    "\n",
    "        ###########################  HR+FAR ############################\n",
    "        co, co_pred, event_count,h,fa,ms,cn,hr,far,recall,precision,f1= cont_calc(truth,preds,method, threshold, co_buffer)\n",
    "\n",
    "        if lead==3:\n",
    "            if co.sum()>0:\n",
    "                #print('crisis onsets registered:', co_counting)\n",
    "                print (unit)\n",
    "                print ('now printing truths and preds')\n",
    "                print(truth)\n",
    "                print (preds)\n",
    "                print ('now printing hr and far ,co, co_preds')\n",
    "                print (hr, far, co, co_pred)\n",
    "\n",
    "\n",
    "        ############################ Mean Absolute Error (MAE) #############################\n",
    "        mae = mean_absolute_error(truth, preds)\n",
    "        mae_baseline= mean_absolute_error(truth, base1)\n",
    "        mae_baseline2= mean_absolute_error(truth, base2)\n",
    "        #mae_lr= mean_absolute_error(truth, lr)\n",
    "\n",
    "        ############## RMSE ##############\n",
    "        rmse = mean_squared_error(truth, preds, squared = False)\n",
    "        rmse_baseline= mean_squared_error(truth, base1, squared = False)\n",
    "        rmse_baseline2= mean_squared_error(truth, base2, squared = False)\n",
    "        #rmse_lr= mean_squared_error(truth, lr, squared = False)\n",
    "\n",
    "        ############# R2 #############\n",
    "        r2=r2_score(truth, preds)\n",
    "        r2_baseline=r2_score(truth, base1)\n",
    "        r2_baseline2=r2_score(truth, base2)\n",
    "        #r2_lr=r2_score(truth, lr)\n",
    "\n",
    "        ##################################################################\n",
    "        #######################  FEWS scores ################################\n",
    "\n",
    "\n",
    "        ############################ Mean Absolute Error (MAE) #############################\n",
    "        if fews_preds.isnull().all():\n",
    "            mae_fews= np.nan\n",
    "        else: \n",
    "            mae_fews= mean_absolute_error(truth_FSO, fews_preds) \n",
    "\n",
    "\n",
    "        ############## RMSE ##############\n",
    "        if fews_preds.isnull().all():\n",
    "            rmse_fews= np.nan\n",
    "        else: \n",
    "            rmse_fews=mean_squared_error(truth_FSO, fews_preds,squared = False)     \n",
    "\n",
    "\n",
    "        ############# R2 #############    \n",
    "        if fews_preds.isnull().all():\n",
    "            r2_fews= np.nan\n",
    "        else: \n",
    "            r2_fews= r2_score(truth_FSO, fews_preds)\n",
    "\n",
    "\n",
    "        co_fews,co_pred_fews,event_count_fews, h_fews, fa_fews, ms_fews, cn_fews, hr_fews, far_fews, recall_fews, precision_fews, f1_fews = cont_calc(truth_FSO,fews_preds,method, threshold, co_buffer)\n",
    "\n",
    "\n",
    "        county_eval= pd.DataFrame(data = {'county': unit,\n",
    "                                        'event_count': event_count,\n",
    "                                        'lead': lead,\n",
    "                                        'mae': mae,\n",
    "                                        'mae_baseline': mae_baseline,\n",
    "                                        'mae_baseline2': mae_baseline2,\n",
    "                                         #'mae_lr': mae_lr,\n",
    "                                        'mae_fews': mae_fews,\n",
    "                                        'rmse': rmse,\n",
    "                                        'rmse_baseline': rmse_baseline,\n",
    "                                        'rmse_baseline2': rmse_baseline2,\n",
    "                                         #'rmse_lr': rmse_lr,\n",
    "                                        'rmse_fews': rmse_fews,\n",
    "                                        'r2': r2,\n",
    "                                        'r2_baseline': r2_baseline,\n",
    "                                        'r2_baseline2': r2_baseline2,\n",
    "                                         #'r2_lr': r2_lr,\n",
    "                                        'r2_fews':r2_fews,\n",
    "                                        'far': far, \n",
    "                                        'hr':hr,\n",
    "                                        'f1_score': f1,\n",
    "\n",
    "                                        'far_fews': far_fews,\n",
    "                                        'hr_fews': hr_fews,\n",
    "                                        'f1_score_fews':f1_fews }, index=[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        eval_stats=pd.concat([eval_stats, county_eval], axis=0) # preds_storage defined in beginning of script\n",
    "\n",
    "####################################################### R2 processing ##############################################\n",
    "eval_stats.loc[eval_stats['r2']<0, 'r2']=0\n",
    "eval_stats.loc[eval_stats['r2_baseline']<0, 'r2_baseline']=0\n",
    "eval_stats.loc[eval_stats['r2_baseline2']<0, 'r2_baseline2']=0\n",
    "#eval_stats.loc[eval_stats['r2_lr']<0, 'r2_lr']=0\n",
    "eval_stats.loc[eval_stats['r2_fews']<0, 'r2_fews']=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial eval plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_var= 'hr' # can be normal eval stats or ending with '_fews' for the fews stats\n",
    "lead=3\n",
    "\n",
    "color1=Color(\"green\")\n",
    "color2=Color(\"red\")\n",
    "\n",
    "eval_stats_lead=eval_stats[eval_stats['lead']==lead]\n",
    "# delete nan rows from eval_stats\n",
    "if plot_var=='f1_score':\n",
    "    eval_stats_lead=eval_stats_lead[eval_stats_lead['event_count']>=1]\n",
    "\n",
    "if (plot_var=='hr')|(plot_var=='hr_fews')|(plot_var=='far')|(plot_var=='far_fews'):\n",
    "    eval_stats_lead=eval_stats_lead[eval_stats_lead['event_count']>=1]\n",
    "########### VERIFICATION MAPS ###############        #https://residentmario.github.io/geoplot/plot_references/plot_reference.html\n",
    "eval_stats_lead['mae_ref']=eval_stats_lead['mae_baseline']-eval_stats_lead['mae'] # to show improvement compared to baseline\n",
    "\n",
    "#eval_stats_lead['mae_%']= ((eval_stats_lead['mae']-eval_stats_lead['mae_baseline'])/(eval_stats_lead['mae_baseline']+0.01))*100 #Percentage Decrease = [(Original value – New value)/Original value] × 100\n",
    "#for plot_var in ['mae', 'rmse', 'r2']:\n",
    "#plot_var='mae_ref' # variable to plot\n",
    "#for lead in eval_stats['lead'].unique():\n",
    "\n",
    "\n",
    "if extent=='Kenya':\n",
    "    county_sf=gpd.read_file(VECTOR_FOLDER+'geo_boundaries/Kenya/County.shp')\n",
    "    county_sf.rename(columns={'COUNTY':'county'}, inplace=True)\n",
    "\n",
    "if extent=='Ethiopia':\n",
    "    county_sf=gpd.read_file(VECTOR_FOLDER+'geo_boundaries/Ethiopia/eth_admbnda_adm2_csa_bofedb_2021.shp')\n",
    "    county_sf.rename(columns={'ADM2_EN':'county'}, inplace=True) \n",
    "if extent=='Somalia':\n",
    "    county_sf=gpd.read_file(VECTOR_FOLDER+'geo_boundaries/Somalia/Som_Admbnda_Adm2_UNDP.shp')\n",
    "    county_sf.rename(columns={'admin2Name':'county'}, inplace=True) \n",
    "\n",
    "if extent=='HOA':\n",
    "    county_sf=gpd.read_file(VECTOR_FOLDER+'geo_boundaries/HOA/HOA.shp')\n",
    "\n",
    "#ax = gplt.polyplot(county_sf, projection=gcrs.AlbersEqualArea())\n",
    "fig, ax = plt.subplots(1, 1,figsize=(12,10),subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "#print (len(county_sf.county.unique()))\n",
    "\n",
    "# plot cartopy features --> https://stackoverflow.com/questions/67508054/improve-resolution-of-cartopy-map\n",
    "\n",
    "ax.add_feature(cartopy.feature.LAND)\n",
    "ax.add_feature(cartopy.feature.OCEAN)\n",
    "ax.add_feature(cartopy.feature.COASTLINE,linewidth=0.5)\n",
    "ax.add_feature(cartopy.feature.BORDERS, linestyle='-',linewidth=1)\n",
    "#ax.add_feature(cartopy.feature.LAKES, alpha=0.5)\n",
    "#ax.add_feature(cartopy.feature.RIVERS)\n",
    "\n",
    "plot_vals=eval_stats_lead[[plot_var, 'county']] \n",
    "county_sf=pd.merge(county_sf, plot_vals, on='county')\n",
    "county_sf= county_sf[~county_sf[plot_var].isna()]\n",
    "county_sf=county_sf[['geometry', plot_var]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if (plot_var=='r2')|(plot_var=='r2_fews'):\n",
    "    bin_edges=[0, 0.25, 0.5, 0.75,1]\n",
    "if (plot_var=='mae')|(plot_var=='mae_fews'):\n",
    "    bin_edges= list(np.round(np.arange(0.0,1.1,0.1),2))\n",
    "\n",
    "if (plot_var=='f1_score')|(plot_var=='f1_score_fews'):\n",
    "    bin_edges= list(np.round(np.arange(0.0,1.1,0.25),2))\n",
    "    \n",
    "if (plot_var=='hr')|(plot_var=='hr_fews')|(plot_var=='far')|(plot_var=='far_fews'):\n",
    "    bin_edges= list(np.round(np.arange(0.0,1.1,0.25),2))\n",
    "\n",
    "\n",
    "# attach class to class column on county_sf with loop. Base on bin_edges\n",
    "for i in range(len(bin_edges)):\n",
    "    #if i==0:\n",
    "    # first class\n",
    "    #county_sf.loc[county_sf[plot_var]<=bin_edges[0], 'class']= '<%s'%(bin_edges[0])\n",
    "    #else:\n",
    "    # other classes\n",
    "    county_sf.loc[(county_sf[plot_var]>=bin_edges[i-1]) & (county_sf[plot_var]<=bin_edges[i]), 'class']= '%s- %s'%(bin_edges[i-1],bin_edges[i])\n",
    "    \n",
    "    county_sf.loc[county_sf[plot_var]>bin_edges[-1], 'class']= '>%s'%(bin_edges[-1])\n",
    "    \n",
    "county_sf=county_sf.sort_values(by='class')\n",
    "\n",
    "if len(county_sf[county_sf['class'].isna()])>0:\n",
    "    print(county_sf[county_sf['class'].isna()])\n",
    "\n",
    "if plot_var=='mae' or plot_var=='mae_fews':\n",
    "    colors = list(color1.range_to(color2,len(bin_edges)))\n",
    "    hepex_list= [color.hex for color in colors]\n",
    "\n",
    "    color_dict = dict(zip(county_sf['class'].unique(), hepex_list))  \n",
    "\n",
    "    color_dict = {key: color_dict[key]\n",
    "                 for key in color_dict if key not in  list(set(color_dict)-set(county_sf['class'].unique()))\n",
    "                 }\n",
    "else:\n",
    "    #desired color dict\n",
    "    color_dict={'0.0- 0.25': '#f00',\n",
    "     '0.25- 0.5': '#df7000',\n",
    "     '0.5- 0.75': '#bfbf00',\n",
    "     '0.75- 1.0': '#50a000'}\n",
    "\n",
    "#map_dict = dict(zip(color_dict.keys(),[x for x in range(len(color_dict))]))\n",
    "county_sf['colour'] = county_sf['class'].apply(lambda x: color_dict[x])\n",
    "\n",
    "# add color scheme\n",
    "color_scheme_map = list(color_dict.values())\n",
    "cmap = LinearSegmentedColormap.from_list(name='landuse',\n",
    "                                     colors=color_scheme_map)  \n",
    "\n",
    "# and plot the map\n",
    "county_sf.plot(color=county_sf['colour'],ax=ax,linewidth=0.5, edgecolor='black')\n",
    "\n",
    "# remove the ax labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_axis_off()\n",
    "\n",
    "# add a legend:\n",
    "legend_elements = []\n",
    "for iter_,item in enumerate(color_dict):\n",
    "    legend_elements.append(Patch(facecolor=color_scheme_map[iter_],label=item))        \n",
    "\n",
    "ax.legend(handles=legend_elements,edgecolor='black',facecolor='#fefdfd',prop={'size':12},loc=(1.02,0.2)) \n",
    "\n",
    "# labels \n",
    "\n",
    "# Calculate the centroid for each county\n",
    "county_sf['coords'] = county_sf['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "county_sf['coords'] = [coords[0] for coords in county_sf['coords']]\n",
    "\n",
    "# Annotate the plot with the values\n",
    "for idx, row in county_sf.iterrows():\n",
    "    ax.annotate(text=str(row[plot_var]), xy=row['coords'], xytext=(0, 0), textcoords=\"offset points\", ha='center')\n",
    "# add a title\n",
    "ax.set_title('%s for %s for lead %s for %s'%(plot_var, method,lead, extent),fontweight='bold')\n",
    "plt.savefig(paper_plots+'verif_map_lead_%s_%s_%s_%s.pdf'%(lead,extent,plot_var,experiment), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DASHBOARD TIMESERIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead=3\n",
    "eval_var='r2'\n",
    "plot_df=preds_storage_master[preds_storage_master['lead']==lead]\n",
    "#plot_df=plot_df[plot_df['cluster']=='other']\n",
    "counties=plot_df.county.unique()\n",
    "plot_by='eval' # 'eval' or 'variance'\n",
    "\n",
    "\n",
    "\n",
    "################################## variance per county ##################################\n",
    "variances=[]\n",
    "for county in counties:\n",
    "    county_df=plot_df[plot_df['county']==county]\n",
    "    variances.append(county_df.observed.var())\n",
    "\n",
    "counties_df=pd.DataFrame({'county':counties,'variance':variances})\n",
    "\n",
    "counties_df=counties_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "################################### eval per county #####################################\n",
    "\n",
    "evals=[]\n",
    "for county in counties:\n",
    "    county_df=eval_stats[eval_stats['county']==county]\n",
    "    county_df=county_df[county_df['lead']==lead]\n",
    "    evals.append(county_df[eval_var].mean())\n",
    "\n",
    "counties_df=pd.DataFrame({'county':counties,'eval':evals, 'variance':variances})\n",
    "\n",
    "\n",
    "\n",
    "################################### plot by eval or variance #####################################\n",
    "\n",
    "\n",
    "\n",
    "if plot_by=='variance':\n",
    "    counties_df=counties_df[['county', 'variance']]\n",
    "    eval_sorted=counties_df.sort_values(by='variance',ascending=False)\n",
    "    counties_plot=eval_sorted.head(45).county.values\n",
    "if plot_by=='eval':\n",
    "    counties_df=counties_df[['county', 'eval']]\n",
    "    eval_sorted=counties_df.sort_values(by='eval',ascending=False)\n",
    "    counties_plot=eval_sorted.head(45).county.values\n",
    "\n",
    "\n",
    "################################### plot section #####################################\n",
    "fig=plt.figure(figsize=(40,20))# (W,H)\n",
    "gs=fig.add_gridspec(3,15,wspace=0.1,hspace=0.5)\n",
    "\n",
    "indexer=0\n",
    "for i in range(gs.nrows):\n",
    "    for j in range(gs.ncols):\n",
    "        \n",
    "        # select county data\n",
    "        county=counties_plot[indexer]\n",
    "        #print (county)\n",
    "        ax=fig.add_subplot(gs[i,j])\n",
    "\n",
    "\n",
    "        county_df=plot_df[plot_df['county']==county]\n",
    "\n",
    "        #plot details \n",
    "        ax.plot(county_df.prediction,label='Model predictions',color='red',linestyle='--',linewidth=2)\n",
    "        #ax.plot(county_df.base1_preds,label='Baseline predictions',color='green',linestyle='--',linewidth=4)\n",
    "        #ax.plot(county_df.base2_preds,label='Baseline2 predictions',color='orange',linestyle='--',linewidth=4)\n",
    "        \n",
    "        ax.plot(county_df.observed,label='Observations',color='blue',linestyle='-',linewidth=2)\n",
    "        ax.set_title(county,size=20)\n",
    "        ax.set_xlabel('Time',size=20)\n",
    "        ax.set_ylabel('Food insecurity (FEWS IPC)',size=20)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        ax.tick_params(axis='both', which='minor', labelsize=20)\n",
    "        ax.grid()\n",
    "\n",
    "        # extract the county mae from the eval_stats df\n",
    "        county_eval=eval_stats[eval_stats['county']==county]\n",
    "        county_eval=county_eval[county_eval['lead']==lead]\n",
    "        # Make a R2 string (squared) I want the square to be a superscript\n",
    "        ax.text(0.1, 0.8, 'R$^2$ :'+str(round(county_eval[eval_var].values[0],2)), horizontalalignment='left',verticalalignment='center', fontweight='bold', transform=ax.transAxes,fontsize=20)\n",
    "        # mae_baseline \n",
    "        eval_value=county_eval[eval_var+'_baseline'].values[0]\n",
    "        eval_value=round(eval_value,2)\n",
    "        #ax.text(0.1, 0.92, 'R$^2$ persistence: '+str(eval_value), horizontalalignment='left',verticalalignment='center', transform=ax.transAxes,fontsize=10)\n",
    "        # mae_baseline2\n",
    "        county_eval=eval_stats[eval_stats['county']==county][eval_var+'_baseline2'].values[0]\n",
    "        county_eval=round(county_eval,2)\n",
    "        #ax.text(0.1, 0.89, 'R$^2$ seasonality: '+str(county_eval), horizontalalignment='left',verticalalignment='center', transform=ax.transAxes,fontsize=10)\n",
    "\n",
    "        # rotate x axis labels 90 degrees\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=20)\n",
    "        ax.set_ylim([1, 4])\n",
    "\n",
    "        ax.set_facecolor('lightgrey')\n",
    "\n",
    "        # Get current x-ticks and labels\n",
    "        xticks = ax.get_xticks()\n",
    "        xticklabels = ax.get_xticklabels()\n",
    "\n",
    "        # Set new x-ticks and labels to be every other one\n",
    "        ax.set_xticks(xticks[::2])  # Change this to control the frequency\n",
    "        ax.set_xticklabels(xticklabels[::2], rotation=90, fontsize=20)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        indexer+=1\n",
    "\n",
    "list_of_numbers=list(range(0,45))\n",
    "list_of_numbers.remove(0)\n",
    "list_of_numbers.remove(15)\n",
    "list_of_numbers.remove(30)\n",
    "\n",
    "for i in list_of_numbers:\n",
    "    fig.axes[i].yaxis.set_visible(True)\n",
    "    fig.axes[i].yaxis.set_ticklabels([])\n",
    "    fig.axes[i].set_ylabel('')\n",
    "\n",
    "\n",
    "# I want to delete axis labels and ticks of the x-axis for all but the bottom row\n",
    "for i in range(0,30):\n",
    "    fig.axes[i].xaxis.set_visible(True)\n",
    "    #fig.axes[i].xaxis.set_ticklabels([])\n",
    "    fig.axes[i].set_xlabel('')\n",
    "\n",
    "\n",
    "plt.legend(loc='lower center', bbox_to_anchor=(-0.5, -2),ncol=1,fontsize=20)\n",
    "plt.savefig(paper_plots+'timeseries.pdf',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lead time graphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### calculate evaluation metrics over the countries or lhz #################################\n",
    "preds_storage_plot=preds_storage_master.copy()\n",
    "\n",
    "total_df=pd.DataFrame()\n",
    "\n",
    "# aggregation for evaluation plot \n",
    "\n",
    "units=preds_storage_plot.cluster.unique() # country or cluster\n",
    "unit_level= 'cluster' # 'country' or 'cluster'\n",
    "\n",
    "for unit in units:\n",
    "    units_data= preds_storage_plot[preds_storage_plot[unit_level]==unit]\n",
    "    \n",
    "    for lead in preds_storage_plot.lead.unique(): \n",
    "        data_lead= units_data[units_data['lead']==lead]\n",
    "        \n",
    "        # R2 \n",
    "        r2= r2_score(data_lead['observed'], data_lead['prediction'])\n",
    "        r2_baseline= r2_score(data_lead['observed'], data_lead['base1_preds'])\n",
    "        r2_baseline2= r2_score(data_lead['observed'], data_lead['base2_preds'])\n",
    "\n",
    "        # MAE\n",
    "        mae= mean_absolute_error(data_lead['observed'], data_lead['prediction'])\n",
    "        mae_baseline= mean_absolute_error(data_lead['observed'], data_lead['base1_preds'])\n",
    "        mae_baseline2= mean_absolute_error(data_lead['observed'], data_lead['base2_preds'])\n",
    "\n",
    "        # HR and FAR\n",
    "        \n",
    "        # ML preds\n",
    "        co, co_pred,event_count,h,fa,ms,cn,hr,far,recall,precision,f1= cont_calc(data_lead['observed'],data_lead['prediction'],method, threshold, co_buffer)    \n",
    "        hr_ML=hr.copy()\n",
    "        far_ML=far.copy()\n",
    "        \n",
    "        # base1_preds\n",
    "        co,co_pred,event_count,h,fa,ms,cn,hr,far,recall,precision,f1= cont_calc(data_lead['observed'],data_lead['base1_preds'],method, threshold, co_buffer)\n",
    "        hr_baseline=hr.copy()\n",
    "        far_baseline=far.copy()\n",
    "        \n",
    "        # base2 preds\n",
    "        co,co_pred,event_count,h,fa,ms,cn,hr,far,recall,precision,f1= cont_calc(data_lead['observed'],data_lead['base2_preds'],method, threshold, co_buffer)\n",
    "        hr_baseline2=hr.copy()\n",
    "        far_baseline2=far.copy()\n",
    "        \n",
    "        # FEWS scores \n",
    "        if (lead==0 or lead==12): # these leads do not exist for FEWS \n",
    "            r2_fews= np.nan\n",
    "            mae_fews=np.nan\n",
    "            hr_fews=np.nan\n",
    "            far_fews=np.nan\n",
    "        \n",
    "        else: \n",
    "            truth_FSO=data_lead['OBS_FSO'][~np.isnan(data_lead['OBS_FSO'])]            \n",
    "            fews_preds= data_lead['FEWS_prediction'][~np.isnan(data_lead['FEWS_prediction'])]\n",
    "            \n",
    "            r2_fews=r2_score(truth_FSO,fews_preds) \n",
    "            mae_fews= mean_absolute_error(truth_FSO,fews_preds)\n",
    "            \n",
    "            co_fews,co_pred_fews,event_count_fews, h_fews, fa_fews, ms_fews, cn_fews, hr_fews, far_fews, recall_fews, precision_fews, f1_fews = cont_calc(truth_FSO,fews_preds,method, threshold, co_buffer)\n",
    "                \n",
    "                \n",
    "        # concat to df\n",
    "        total_df=pd.concat([total_df, pd.DataFrame({'unit':unit, 'event_count':event_count,'lead':lead, 'r2':r2, 'r2_baseline':r2_baseline, 'r2_baseline2':r2_baseline2, 'mae':mae, 'mae_baseline':mae_baseline, 'mae_baseline2':mae_baseline2, 'hr':hr_ML, 'hr_baseline':hr_baseline, 'hr_baseline2':hr_baseline2, 'far':far_ML, 'far_baseline':far_baseline, 'far_baseline2':far_baseline2, 'hr_fews': hr_fews, 'far_fews':far_fews, 'r2_fews':r2_fews, 'mae_fews':mae_fews}, index=[0])])\n",
    "        #print(total_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(preds_storage_master[preds_storage_master['cluster']=='ap'].county.unique()))\n",
    "print(len(preds_storage_master[preds_storage_master['cluster']=='p'].county.unique()))\n",
    "print(len(preds_storage_master[preds_storage_master['cluster']=='other'].county.unique()))\n",
    "print(units_data[units_data['lead']==12].tail(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lead time overview plot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper lead time plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############################################# PAPER R2 PLOT  ########################################################\n",
    "fig, ax = plt.subplots(1,3, figsize=(8,3), sharex=True, sharey=True)\n",
    "\n",
    "# Area 1 \n",
    "data_1= total_df[total_df['unit']=='p']  # Kenya or p\n",
    "\n",
    "# R2\n",
    "ax[0].plot(data_1['lead'], data_1['r2'], label='r2', color='green', linewidth=2, linestyle='--')\n",
    "ax[0].plot(data_1['lead'], data_1['r2_baseline'], label='r2 baseline', color='black', linewidth=2, linestyle='--')\n",
    "ax[0].plot(data_1['lead'], data_1['r2_baseline2'], label='r2 baseline2', color='magenta', linewidth=2, linestyle='--')\n",
    "ax[0].plot(data_1['lead'], data_1['r2_fews'], label='r2 fews fso', color='#FFA51B', linewidth=2, linestyle='--')\n",
    "\n",
    "ax[0].set_title('Pastoralism')\n",
    "ax[0].set_ylabel('Coefficient of determination (R$^2$)')\n",
    "ax[0].set_xlabel('lead time (months)')\n",
    "\n",
    "\n",
    "# Area 2  \n",
    "data_2= total_df[total_df['unit']=='ap'] # Ethiopia or ap\n",
    "\n",
    "# R2\n",
    "ax[1].plot(data_2['lead'], data_2['r2'], label='r2', color='green', linewidth=2, linestyle='--')\n",
    "ax[1].plot(data_2['lead'], data_2['r2_baseline'], label='r2 baseline', color='black', linewidth=2, linestyle='--')\n",
    "ax[1].plot(data_2['lead'], data_2['r2_baseline2'], label='r2 baseline2', color='magenta', linewidth=2, linestyle='--')\n",
    "ax[1].plot(data_2['lead'], data_2['r2_fews'], label='r2 fews fso', color='#FFA51B', linewidth=2, linestyle='--')\n",
    "\n",
    "ax[1].set_title('agro-pastoralism')\n",
    "#ax[1].set_ylabel('Coefficient of determination (R$^2$)')\n",
    "ax[1].set_xlabel('lead time (months)')\n",
    "\n",
    "# Area 3 \n",
    "data_3= total_df[total_df['unit']=='other'] # Somalia or other \n",
    "\n",
    "# R2\n",
    "ax[2].plot(data_3['lead'], data_3['r2'], label='R$^2$ XGBoost model', color='green', linewidth=2, linestyle='--')\n",
    "ax[2].plot(data_3['lead'], data_3['r2_baseline'], label='R$^2$ persistence model ', color='black', linewidth=2, linestyle='--')\n",
    "ax[2].plot(data_3['lead'], data_3['r2_baseline2'], label='R$^2$ seasonality model', color='magenta', linewidth=2, linestyle='--')\n",
    "ax[2].plot(data_3['lead'], data_3['r2_fews'], label='R$^2$ FEWS outlooks', color='#FFA51B', linewidth=2, linestyle='--')\n",
    "\n",
    "ax[2].set_title('Crop farming')\n",
    "#ax[2].set_ylabel('Coefficient of determination (R$^2$)')\n",
    "ax[2].set_xlabel('lead time (months)')\n",
    "\n",
    "\n",
    "plt.ylim(0,0.78)\n",
    "plt.xlim(0,12)\n",
    "# x ticks 0,1,2,3,4,8,12\n",
    "plt.xticks([0,1,2,3,4,8,12])\n",
    "\n",
    "# gridlines and background color \n",
    "ax[0].grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "ax[1].grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "ax[2].grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "\n",
    "ax[0].set_facecolor('whitesmoke') \n",
    "ax[1].set_facecolor('whitesmoke')\n",
    "ax[2].set_facecolor('whitesmoke')\n",
    "\n",
    "\n",
    "#fig.suptitle('R2 score for different lead times', fontsize=16)\n",
    "# legend outside of plot \n",
    "plt.legend(loc='upper center', bbox_to_anchor=(1.7, 1.05), ncol=1, fancybox=True, shadow=True)\n",
    "\n",
    "plt.savefig(paper_plots+'R2_timeline.pdf',bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################# PLOT Paper HR-FAR ########################################################\n",
    "\n",
    "fig, ax = plt.subplots(1,6, figsize=(20,5), sharex=True, sharey=True)\n",
    "line_width_var= 2\n",
    "\n",
    "\n",
    "# Area 1 --> pastoralists \n",
    "data_1= total_df[total_df['unit']=='p']  # Kenya or p \n",
    "\n",
    "\n",
    "# HR\n",
    "ax[0].plot(data_1['lead'], data_1['hr'], label='XGBoost model', color='green', linewidth=line_width_var, linestyle='--')\n",
    "ax[0].plot(data_1['lead'], data_1['hr_baseline'], label='Persistence model', color='black', linewidth=line_width_var, linestyle='--')\n",
    "ax[0].plot(data_1['lead'], data_1['hr_baseline2'], label='Seasonality model', color='magenta', linewidth=line_width_var, linestyle='--')\n",
    "ax[0].plot(data_1['lead'], data_1['hr_fews'], label='FEWS outlooks', color='#FFA51B', linewidth=line_width_var, linestyle='--')\n",
    "\n",
    "ax[0].set_title('Pastoralism', fontsize=15)\n",
    "ax[0].set_ylabel('Hit Rate (HR)', fontsize=15)\n",
    "ax[0].set_xlabel('lead time (months)', fontsize=15)\n",
    "\n",
    "# FAR\n",
    "ax[1].plot(data_1['lead'], data_1['far'], label='XGBoost model', color='green', linewidth=line_width_var, linestyle='--')\n",
    "ax[1].plot(data_1['lead'], data_1['far_baseline'], label='Persistence model', color='black', linewidth=line_width_var, linestyle='--')\n",
    "ax[1].plot(data_1['lead'], data_1['far_baseline2'], label='Seasonality model', color='magenta', linewidth=line_width_var, linestyle='--')\n",
    "ax[1].plot(data_1['lead'], data_1['far_fews'], label='FEWS outlooks', color='#FFA51B', linewidth=line_width_var, linestyle='--')\n",
    "\n",
    "\n",
    "ax[1].set_ylabel('False Alarm Rate (FAR)', fontsize=15)\n",
    "ax[1].set_xlabel('lead time (months)', fontsize=15)\n",
    "\n",
    "\n",
    "# Area 2 --> agropastoralists\n",
    "data_2= total_df[total_df['unit']=='ap'] # Ethiopia or ap \n",
    "\n",
    "# HR\n",
    "ax[2].plot(data_2['lead'], data_2['hr'], label='XGBoost model', color='green', linewidth=line_width_var, linestyle='--')\n",
    "ax[2].plot(data_2['lead'], data_2['hr_baseline'], label='Persistence model', color='black', linewidth=line_width_var, linestyle='--')\n",
    "ax[2].plot(data_2['lead'], data_2['hr_baseline2'], label='Seasonality model', color='magenta', linewidth=line_width_var, linestyle='--')\n",
    "ax[2].plot(data_2['lead'], data_2['hr_fews'], label='FEWS outlooks', color='#FFA51B', linewidth=line_width_var, linestyle='--')\n",
    "\n",
    "\n",
    "ax[2].set_title('Agro-pastoralism', fontsize=15)\n",
    "ax[2].set_ylabel('Hit Rate (HR)', fontsize=15)\n",
    "ax[2].set_xlabel('lead time (months)', fontsize=15)\n",
    "\n",
    "# FAR\n",
    "ax[3].plot(data_2['lead'], data_2['far'], label='XGBoost model', color='green', linewidth=line_width_var, linestyle='--')\n",
    "ax[3].plot(data_2['lead'], data_2['far_baseline'], label='Persistence model', color='black', linewidth=line_width_var, linestyle='--')\n",
    "ax[3].plot(data_2['lead'], data_2['far_baseline2'], label='Seasonality model', color='magenta', linewidth=line_width_var, linestyle='--')\n",
    "ax[3].plot(data_2['lead'], data_2['far_fews'], label='FEWS outlooks', color='#FFA51B', linewidth=line_width_var, linestyle='--')\n",
    "\n",
    "ax[3].set_ylabel('False Alarm Rate (FAR)', fontsize=15)\n",
    "ax[3].set_xlabel('lead time (months)', fontsize=15)\n",
    "\n",
    "# Area 3 --> other (crop farming)\n",
    "data_3= total_df[total_df['unit']=='other'] # Somalia or other\n",
    "\n",
    "#HR\n",
    "ax[4].plot(data_3['lead'], data_3['hr'], label='XGBoost model', color='green', linewidth=line_width_var, linestyle='--')\n",
    "ax[4].plot(data_3['lead'], data_3['hr_baseline'], label='Persistence model', color='black', linewidth=line_width_var, linestyle='--')\n",
    "ax[4].plot(data_3['lead'], data_3['hr_baseline2'], label='Seasonality model', color='magenta', linewidth=line_width_var, linestyle='--')\n",
    "ax[4].plot(data_3['lead'], data_3['hr_fews'], label='FEWS outlooks', color='#FFA51B', linewidth=line_width_var, linestyle='--')\n",
    "\n",
    "\n",
    "ax[4].set_title('Crop farming', fontsize=15)\n",
    "ax[4].set_ylabel('Hit Rate (HR)', fontsize=15)\n",
    "ax[4].set_xlabel('lead time (months)', fontsize=15)\n",
    "\n",
    "# FAR\n",
    "ax[5].plot(data_3['lead'], data_3['far'], label='XGBoost model', color='green', linewidth=line_width_var, linestyle='--')\n",
    "ax[5].plot(data_3['lead'], data_3['far_baseline'], label='Persistence model', color='black', linewidth=line_width_var, linestyle='--')\n",
    "ax[5].plot(data_3['lead'], data_3['far_baseline2'], label='Seasonality model', color='magenta', linewidth=line_width_var, linestyle='--')\n",
    "ax[5].plot(data_3['lead'], data_3['far_fews'], label='FEWS outlooks', color='#FFA51B', linewidth=line_width_var, linestyle='--')\n",
    "\n",
    "\n",
    "ax[5].set_ylabel('False Alarm Rate (FAR)', fontsize=15)\n",
    "ax[5].set_xlabel('lead time (months)', fontsize=15)\n",
    "\n",
    "\n",
    "plt.ylim(0,0.7)\n",
    "plt.xlim(0,12)\n",
    "plt.xticks([0,1,2,3,4,8,12])\n",
    "\n",
    "\n",
    "# size of tick labels\n",
    "ax[0].tick_params(axis='both', which='major', labelsize=15)\n",
    "ax[1].tick_params(axis='both', which='major', labelsize=15)\n",
    "ax[2].tick_params(axis='both', which='major', labelsize=15)\n",
    "ax[3].tick_params(axis='both', which='major', labelsize=15)\n",
    "ax[4].tick_params(axis='both', which='major', labelsize=15)\n",
    "ax[5].tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "\n",
    "# gridlines and background color \n",
    "ax[0].grid(color='black', linestyle='-', linewidth=0.25, alpha=0.4)\n",
    "ax[1].grid(color='black', linestyle='-', linewidth=0.25, alpha=0.4)\n",
    "ax[2].grid(color='black', linestyle='-', linewidth=0.25, alpha=0.4)\n",
    "ax[3].grid(color='black', linestyle='-', linewidth=0.25, alpha=0.4)\n",
    "ax[4].grid(color='black', linestyle='-', linewidth=0.25, alpha=0.4)\n",
    "ax[5].grid(color='black', linestyle='-', linewidth=0.25, alpha=0.4)\n",
    "\n",
    "# ax[0].set_facecolor('whitesmoke') \n",
    "# ax[1].set_facecolor('whitesmoke')\n",
    "# ax[2].set_facecolor('whitesmoke')\n",
    "# ax[3].set_facecolor('whitesmoke')\n",
    "# ax[4].set_facecolor('whitesmoke')\n",
    "# ax[5].set_facecolor('whitesmoke')\n",
    "\n",
    "#fig.suptitle('R2 score for different lead times', fontsize=16)\n",
    "# legend outside of plot \n",
    "plt.legend(loc='upper center', bbox_to_anchor=(1.5, 1.05), ncol=1, fancybox=True, shadow=True)\n",
    "\n",
    "plt.savefig(paper_plots+'HR_timeline.pdf',bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country= 'HOA' # country to plot\n",
    "plot_cluster= None # None or cluster_list\n",
    "cluster= None\n",
    "pred_type='prediction' # base1_preds or prediction or FEWS_prediction\n",
    "obs_type='observed'# OBS_FSO or observed \n",
    "if country!= 'HOA':\n",
    "    preds_storage_plot= preds_storage_master[preds_storage_master['country']==country]\n",
    "\n",
    "else: \n",
    "    preds_storage_plot= preds_storage_master.copy()\n",
    "\n",
    "\n",
    "if plot_cluster!=None: \n",
    "    preds_storage_plot=preds_storage_plot[preds_storage_plot['cluster']==cluster]\n",
    "\n",
    "preds_storage_plot=preds_storage_plot[~np.isnan(preds_storage_plot[pred_type])]\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(10, 10), sharey=True, sharex=False,gridspec_kw={'hspace': 0.4, 'wspace': 0.3, 'width_ratios': [1, 1, 1], 'height_ratios': [1, 1, 1]})\n",
    "fig.suptitle('Scatter plot for %s'%(country), fontsize=16, fontweight='bold', y=0.95)\n",
    "\n",
    "for i in range(len(preds_storage_plot.lead.unique())):\n",
    "    \n",
    "    max_fews= int(round(preds_storage_plot[obs_type].max(),0))\n",
    "    min_fews= int(round(preds_storage_plot[obs_type].min(),0))\n",
    "    margin=0.1\n",
    "    \n",
    "    preds_lead=preds_storage_plot[preds_storage_plot['lead']==preds_storage_plot.lead.unique()[i]]\n",
    "    preds_lead= preds_lead[~np.isnan(preds_lead[pred_type])]\n",
    "    \n",
    "\n",
    "    values = np.vstack([preds_lead[obs_type], preds_lead[pred_type]])\n",
    "    kernel = stats.gaussian_kde(values)(values) #Representation of a kernel-density estimate using Gaussian kernels.\n",
    "\n",
    "    # 1:1 line \n",
    "    axs[i//3, i%3].plot([min_fews-margin, max_fews+margin], [min_fews-margin, max_fews+margin], 'k-', color = 'r')\n",
    "\n",
    "    # scatter \n",
    "    axs[i//3, i%3].scatter(preds_lead[obs_type].values, preds_lead[pred_type].values, c=kernel,cmap=\"viridis\", label='L=%s'%(preds_lead.lead.unique()[0]), s=20)\n",
    "\n",
    "\n",
    "    # format plot\n",
    "    axs[i//3, i%3].set_title('Lead = %s months'%(preds_lead.lead.unique()[0]))\n",
    "\n",
    "    # add R2 as text to plot\n",
    "    slope, intercept, r_value, p_value, std_err = sp.stats.linregress(preds_lead[pred_type].values, preds_lead[obs_type].values)\n",
    "    coef_determination = r2_score(preds_lead[obs_type].values, preds_lead[pred_type].values)\n",
    "    print (lead, coef_determination)\n",
    "    r_squared=r_value**2\n",
    "    axs[i//3, i%3].text(.05, .8, 'R2={:.2f}'.format(coef_determination),\n",
    "            transform=axs[i//3, i%3].transAxes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    axs[i//3, i%3].set_ylim(min_fews-margin,max_fews+margin)\n",
    "    axs[i//3, i%3].set_xlim(min_fews-margin, max_fews+margin)\n",
    "\n",
    "    axs[i//3, i%3].set_xlabel('FEWS observation')\n",
    "\n",
    "    axs[i//3, i%3].set_ylabel('XGBoost prediction')\n",
    "    # convert x tick labels to 0.5 interval \n",
    "    axs[i//3, i%3].set_xticks(np.arange(min_fews, max_fews+0.5, 0.5))\n",
    "    \n",
    "\n",
    "plt.savefig(paper_plots+'scatter_plot.pdf',bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP PLOTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://shap.readthedocs.io/en/latest/example_notebooks/api_examples/plots/beeswarm.html \n",
    "shap_base_master= pd.DataFrame() \n",
    "shap_values_master= pd.DataFrame()\n",
    "shap_data_master= pd.DataFrame()\n",
    "\n",
    "for cluster in cluster_list: \n",
    "    shap_base= pd.read_excel(BASE+'shap_base_values_%s_%s_%s_%s.xlsx'%(aggregation,experiment,region_list[0],cluster), index_col=0)\n",
    "    shap_values= pd.read_excel(BASE+'shap_values_%s_%s_%s_%s.xlsx'%(aggregation,experiment,region_list[0],cluster), index_col=0)\n",
    "    shap_data= pd.read_excel(BASE+'shap_data_%s_%s_%s_%s.xlsx'%(aggregation,experiment,region_list[0],cluster), index_col=0)\n",
    "    \n",
    "\n",
    "    shap_base_master= pd.concat([shap_base_master, shap_base], axis=0)\n",
    "    shap_values_master= pd.concat([shap_values_master, shap_values], axis=0)\n",
    "    shap_data_master= pd.concat([shap_data_master, shap_data], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code to select best performing counties # \n",
    "# EXECUTE ABOVE BLOCK OF CODE ON THE CORRECT LEAD TIME WHEN MAKING THESE PLOTS! \n",
    "seperation_type= 'all' # cluster, country or county  or all\n",
    "cluster='all' # cluster or all \n",
    "country='all' # country or all\n",
    "eval_var='r2' # to filter counties \n",
    "leads=[0,1,2,3,4,8,12]\n",
    "eval_threshold=0.3 # R2 threshold to filter counties\n",
    "lead_for_plot= 8 # lead for spatial plot \n",
    "#counties_plot=[i for i in shap_base_master['county'].unique() if 'Tigray' in i] \n",
    "\n",
    "#print(counties_plot)\n",
    "#leads=[0]\n",
    "filter_on_best=True\n",
    "\n",
    "\n",
    "for lead in leads:\n",
    "    \n",
    "    ################################### COUNTY FILTER #####################################\n",
    "    plot_df=preds_storage_master[preds_storage_master['lead']==lead]\n",
    "    counties=plot_df.county.unique()\n",
    "\n",
    "    ################################### eval per county #####################################\n",
    "\n",
    "    evals=[]\n",
    "    for county in counties:\n",
    "        county_df=eval_stats[eval_stats['county']==county]\n",
    "        county_df=county_df[county_df['lead']==lead]\n",
    "        evals.append(county_df[eval_var].mean())\n",
    "\n",
    "    counties_df=pd.DataFrame({'county':counties,'eval':evals, 'variance':variances})\n",
    "\n",
    "\n",
    "\n",
    "    ################################### plot by eval or variance #####################################\n",
    "    counties_df=counties_df[['county', 'eval']]\n",
    "    eval_sorted=counties_df.sort_values(by='eval',ascending=False)\n",
    "    counties_plot=eval_sorted[eval_sorted['eval']>eval_threshold]['county'].values\n",
    "\n",
    "    if lead==lead_for_plot: \n",
    "        eval_sorted_spatial_plot=eval_sorted[eval_sorted['eval']>eval_threshold]\n",
    "    # select lead \n",
    "    shap_base_master_plot= shap_base_master[shap_base_master['lead']==lead]\n",
    "    shap_values_master_plot= shap_values_master[shap_values_master['lead']==lead]\n",
    "    shap_data_master_plot= shap_data_master[shap_data_master['lead']==lead]\n",
    "\n",
    "    # retrieve countries from the columns Ethiopia, Kenya, Somalia. These are binaries \n",
    "    shap_data_master_plot['country']= shap_data_master_plot[['Ethiopia', 'Kenya', 'Somalia']].idxmax(axis=1)\n",
    "    shap_base_master_plot['country']= shap_data_master_plot['country']\n",
    "    shap_values_master_plot['country']= shap_data_master_plot['country']\n",
    "\n",
    "    if filter_on_best==True: \n",
    "        # keep only the counties which are in counties_plot list \n",
    "        shap_base_master_plot= shap_base_master_plot[shap_base_master_plot['county'].isin(counties_plot)]\n",
    "        shap_values_master_plot= shap_values_master_plot[shap_values_master_plot['county'].isin(counties_plot)]\n",
    "        shap_data_master_plot= shap_data_master_plot[shap_data_master_plot['county'].isin(counties_plot)]\n",
    "\n",
    "    \n",
    "    # select cluster\n",
    "    if seperation_type == 'cluster':\n",
    "\n",
    "        if cluster != 'all':\n",
    "            shap_base_master_plot= shap_base_master_plot[shap_base_master_plot['cluster']==cluster]\n",
    "            shap_values_master_plot= shap_values_master_plot[shap_values_master_plot['cluster']==cluster]\n",
    "            shap_data_master_plot= shap_data_master_plot[shap_data_master_plot['cluster']==cluster]\n",
    "    elif seperation_type == 'county':\n",
    "        shap_base_master_plot= shap_base_master_plot[shap_base_master_plot['county']==county]\n",
    "        shap_values_master_plot= shap_values_master_plot[shap_values_master_plot['county']==county]\n",
    "        shap_data_master_plot= shap_data_master_plot[shap_data_master_plot['county']==county]\n",
    "    else: \n",
    "        if country!='all':\n",
    "            shap_base_master_plot= shap_base_master_plot[shap_base_master_plot['country']==country]\n",
    "            shap_values_master_plot= shap_values_master_plot[shap_values_master_plot['country']==country]\n",
    "            shap_data_master_plot= shap_data_master_plot[shap_data_master_plot['country']==country]\n",
    "        \n",
    "    county_count= shap_base_master_plot['county'].nunique()\n",
    "    print(county_count)\n",
    "    # drop ident columns \n",
    "    drop_cols= ['cluster','lead','county','aggregation','region','country']\n",
    "    shap_base_master_plot.drop(drop_cols, axis=1, inplace=True)\n",
    "    shap_values_master_plot.drop(drop_cols, axis=1, inplace=True)\n",
    "    shap_data_master_plot.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    # build shap explainer\n",
    "    shap_explanation = shap.Explanation(values=shap_values_master_plot.values, base_values=shap_base_master_plot.values, feature_names=shap_values_master_plot.columns, data=shap_data_master_plot.values)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # plot shap values\n",
    "    \n",
    "    # beeswarm plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    shap.plots.beeswarm(shap_explanation, show=False, max_display=10) # beeswarm plot\n",
    "    plt.title('Beeswarm plot for lead %s'%(lead))\n",
    "    plt.savefig(paper_plots+'shap_beeswarm_plot_L%s.pdf'%(lead), bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "#     # bar plot \n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    shap.plots.bar(shap_explanation, show=False) # bar plot\n",
    "    plt.title('Bar plot for lead %s'%(lead))\n",
    "    plt.savefig(paper_plots+'shap_bar_plot_L%s.pdf'%(lead), bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # depedence plot \n",
    "    # fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    # shap.dependence_plot('acled_fatalities', shap_values_master_plot.values, shap_data_master_plot.values,feature_names=shap_data_master_plot.columns, show=False) # dep plot\n",
    "    # plt.title('Dependency plot for lead %s'%(lead))\n",
    "    # plt.show()\n",
    "    # plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# shap.plots.waterfall(shap_values_master_plot\n",
    "# shap.plots.bar(shap_values) #  --> mean of the absolute shap value over each column (feature)\n",
    "# shap.plots.force(shap_values[0])\n",
    "# Dependence plot can be used to show non-linearity (this cannot be seen from the beeswarm plot. )\n",
    "\n",
    "\n",
    "# shap_base_all \n",
    "# shap_values_all\n",
    "\n",
    "# create new explainer from the df's\n",
    "# shap_values_master.drop('cluster', axis=1, inplace=True)\n",
    "\n",
    "# print ('shap done')\n",
    "# exit()\n",
    "\n",
    "\n",
    "####################################### spatial plot #################################\n",
    "# load hoa shapefile \n",
    "county_sf = gpd.read_file(VECTOR_FOLDER+'geo_boundaries/HOA/HOA.shp')\n",
    "\n",
    "# Merge with 'right' to keep only counties in eval_sorted_spatial_plot\n",
    "gdf = pd.merge(county_sf, eval_sorted_spatial_plot, on='county', how='right')\n",
    "\n",
    "gdf = gdf[~gdf['eval'].isna()]\n",
    "gdf = gdf[['geometry', 'eval', 'county']]  # Keep the county column for labels\n",
    "\n",
    "# Convert to Web Mercator\n",
    "gdf = gdf.to_crs(epsg=3857)\n",
    "county_sf = county_sf.to_crs(epsg=3857)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "\n",
    "# Plot the map\n",
    "gdf.plot(ax=ax, linewidth=1, edgecolor='black', cmap='summer_r', column='eval', legend=True, legend_kwds={'label': \"R2\", 'orientation': \"horizontal\", 'shrink': 0.3})\n",
    "\n",
    "# Add the background\n",
    "ctx.add_basemap(ax, source=ctx.providers.Esri.WorldImagery)\n",
    "\n",
    "# Plot the country borders\n",
    "county_sf.boundary.plot(ax=ax, color='black')\n",
    "\n",
    "# Remove x and y labels and ticks\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Remove the attribution text\n",
    "if ax.texts:\n",
    "    # this removes the text from the bottom right corner of the plot\n",
    "    ax.texts[-1].remove()\n",
    "\n",
    "#plt.title('R2 for lead 3')\n",
    "plt.savefig(paper_plots+'spatial_plot_R2_%s.pdf'%(lead_for_plot), bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the percentage of pastoral counties \n",
    "\n",
    "\n",
    "pastoral_counties= preds_storage_master[preds_storage_master['cluster']=='p'].county.unique()\n",
    "\n",
    "\n",
    "\n",
    "# check which county names of pastoral_counties are in the eval_sorted_spatial_plot\n",
    "pastoral_counties_in_plot=[i for i in pastoral_counties if i in eval_sorted_spatial_plot.county.unique()]\n",
    "total_counties_in_plot= eval_sorted_spatial_plot.county.unique()\n",
    "\n",
    "print('percentage of pastoral counties in the best performing counties: ', ((len(pastoral_counties_in_plot))/(len(total_counties_in_plot))*100))\n",
    "\n",
    "#print (pastoral_counties_in_plot)\n",
    "#print(total_counties_in_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shap_values_master"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
